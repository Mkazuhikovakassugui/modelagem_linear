---
title: "Lista de Exercícios 01 - Curso de Modelagem Linear"
author: "Marcio Vakassugui"
date: "2022-08-17"
output: html_document
bibliography: [referencias_exercicio01.bib]
---

## Dados

O banco de dados `Boston` apresenta registros de valores medianos das casas (`medv`) de 506 bairros de Boston. 
O objetivo é identificar quais das 13 variáveis explicativas estão associadas com esses valores e usá-las para fazer predições de preços das casas.

```{r label = 'visualizacao_dados_e_tipos'}
View(MASS::Boston)
dplyr::glimpse(MASS::Boston)
```

```{r label = 'dicionario_dados'}
# Descrição das variáveis
utils::help(Boston)
```

## Exercício 1

Faça um gráfico de dispersão entre `medv` e `rm`.

```{r label = 'exercicio_01_grafico_dispersão_medv_rm'}
#| fig.align = 'center',
#| out.width = '90%',
#| fig.cap = 'fig01 - gráfico de dispersão dos pares valor mediano das casas e número médio de quartos por habitação'

grafico_exercicio_01 <- MASS::Boston |> 
   dplyr::select(medv, rm) |> 
   ggplot2::ggplot()+
   ggplot2::aes(y = medv, x = rm)+
   ggplot2::geom_point(shape = 1, color = '#EAC435')+
   ggplot2::labs(title = 'Gráfico de dispersão',
        subtitle = 'Valor mediano das casas (medv) x número médio de quartos por habitação (rm)')+
   ggplot2::theme_classic()+
   ggplot2::theme(panel.background = ggplot2::element_rect(fill = '#000000'))

grafico_exercicio_01

```
<br><br>

## Exercício 2

Ajuste um modelo de regressão linear simples utilizando `medv` como resposta e `rm` como explicativa e guarde em objeto chamado `mod_simples`. Consulte o `summary(mod_simples)` em seguida.

```{r label = 'exercicio02_modelo_regressao_linear'}

mod_simples <- stats::lm(medv ~ rm, data = MASS::Boston)

summary(mod_simples)

```

## Exercício 3

Sabendo que `medv` é o preço mediano das habitações do bairro e o `rm` é o número médio de quartos por habitação, 

a) interprete o parâmetro `(Intercept)`.

No exercício 02, ajustamos o modelo de regressão linear considerando `medv` como variável resposta e `rm` como variável explicativa. O objetivo era encontrar as **estimadores dos mínimos quadrados**, ou seja, os parâmetros $\hat{\beta }_{0}$ e $\hat{\beta }_{1}$, de modo que o modelo linear resultante fosse o mais próximo possível dos n pontos de dados. Foi utilizada a abordagem dos mínimos quadrados, em que um ajuste foi feito minimizando a soma dos erros ao quadrado.
O parâmetro `intercept` obtido pela função lm do pacote 'stats' corresponde ao parâmetro $\hat{\beta }_{0}$, e pode ser obtido pela seguinte equação de estimação:

$$\hat{\beta }_{0}   = \bar{y} - \hat{\beta }_{1}\bar{x}$$
O `intercept` representa o valor provável do preço mediano das habitações para aquelas com o número médio de quartos igual a zero. <br><br><br>


b) interprete o parâmetro `rm`.

 O parâmetro `rm`, conhecido por `slope`, representa o parâmetro $\hat{\beta }_{1}$ do modelo e pode ser obtido pela equação de estimação:

$$\hat{\beta }_{1}  = \frac{\sum_{i=1}^{n}\left ( x_{i} - \bar{x} \right )(y_{i}-\bar{y})}{\sum_{i=1}^{n }(x_{i} - \bar{x})^{2}}$$

Este parâmetro representa o aumento esperado do preço mediano das habitações para cada aumento na média de quartos de uma unidade no total de quartos da habitação.
<br><br><br>

c) o número de quartos está associado com o valor da habitação? Por quê?

Sim, o número de quartos está associado com o valor da habitação. 

Vamos analisar esta questão, partindo do seguinte teste de hipótese:

'O número médio de quartos por habitação **não** possui associação com o valor mediano das casas'
<br><br>

$\left\{ \begin{array}{cl}
H0 & : \ \hat{\beta }_{1} = 0 \\
Ha & : \ \hat{\beta }_{1} \neq  0
\end{array} \right.$

<br>

Ao analisar os resultados obtidos no exercício 02, observa-se que que o `t-value` obtido para o parâmetro `rm` (número médio de quartos por habitação) foi de 21,72, o que torna absurda a hipótese nula, pois este valor afasta-se significativamente da zona provável de valores para a hipótese analisada.

O `valor-p`, que representa a probabilidade de encontrarmos o valor de 21,72 (*t-value*) na zona provável de valores para a hipótese de que o número médio de quartos por habitação **não** possui associação com o valor mediano das casas é muito próximo de zero, portanto podemos **refutar** a hipótese nula.

Conclui-se, portanto, que o número médio de quartos está associado ao valor mediano das habitações.

## Exercício 4

Consulte as saídas das funções 

- `coef(mod_simples)`
- `confint(mod_simples)`
- `predict(mod_simples)`
- `predict(mod_simples, interval = "confidence")`
- `augment(mod_simples)`

```{r}
stats::coef(mod_simples)
```

a funçao coef extrai coeficientes de objetos que retornam de funções de modelagem.

```{r}
confint(mod_simples)
```
A funçao confint do pacote stats calcula os intervalos de confiança para um ou mais parâmetros em um modelo ajustado.

Esta é uma função genérica. O método padrão presume normalidade, e precisa que as funções coef e vcov estejam disponíveis.


```{r}
predict(mod_simples) |> 
  head(n = 100)
```


```{r}
predict(mod_simples, interval = "confidence") |> 
  head(n = 100)
```


```{r}

broom::augment(mod_simples)

```


## Exercício 5

Usando o data.frame gerado por `augment(mod_simples)` faça um gráfico de `medv` versus `rm` e em seguida desenhe a reta ajustada do `mod_simples`.

```{r label='exercicio5_grafico_dispersao'}
#| fig.align = 'center',
#| out.width = '90%'

graf_ex05 <- broom::augment(mod_simples) |>
  dplyr::select(medv, rm) |>
  ggplot2::ggplot() +
  ggplot2::aes(
    y = medv,
    x = rm
  ) +
  ggplot2::geom_point(shape = 1, color = "#EAC435") +
  ggplot2::geom_smooth(method = "lm", se = FALSE, color = "#F3752B") +
  ggplot2::labs(
    title = "Gráfico de dispersão e modelo de regressão linear ajustado",
    subtitle = "Valor mediano das casas (medv) x número médio de quartos por habitação (rm)"
  ) +
  ggpubr::stat_regline_equation(ggplot2::aes(label = paste(..eq.label..,
    ..rr.label..,
    sep = "*plain(\",\")~~"
  )),
  color = "#F3752B"
  ) +
  ggplot2::theme_classic() +
  ggplot2::theme(panel.background = ggplot2::element_rect(fill = "#000000"))
  

graf_ex05


```

## Exercício 6

Faça um gráfico de resíduos. Coloque os **resíduos** no eixo Y e os **valores ajustados** no eixo X.

```{r}
#| fig.align = 'center',
#| out.width = '90%'

residuos <- broom::augment(mod_simples) |> 
  dplyr::select(.resid, .fitted) |> 
  ggplot2::ggplot()+
  ggplot2::aes(x = .fitted, y = .resid)+
  ggplot2::geom_point(shape = 1, size = 2, color = '#EAC435')+
  ggplot2::geom_line(ggplot2::aes(x = .fitted, y = 0, color = 'red'),
                     linetype = 2)+
  ggplot2::labs(
    title = 'Residuals x Fitted',
    x = 'Residuals',
    y = 'Fitted Values'
  )+
  ggplot2::theme_classic()+
  ggplot2::theme(
    panel.background = ggplot2::element_rect(fill = '#000000'),
    legend.position = 'none')

residuos
   
#ver <- plot(mod_simples, col = '#FFFFFF', bg = par('bg'))

```


## Exercício 7

Observe os gráficos de `plot(mod_simples)`.

```{r}
#| fig.align = 'center',
#| out.width = '90%'

op <- par(bg = '#000000')

graphics::par(mfrow = c(1,1), bty = 'l', col = '#FFFFFF')
plot(mod_simples, bg = par('bg'), col = '#EAC435', col.axis = "#FFFFFF", col.lab = "thistle") 
```
<br><br>
Apenas pela inspeção visual, responda: existem outliers? Eles são pontos de alavanca?

A existência de outliers e de pontos de alavancagem pode ser analisada por meio do gráfico 'Residuals vs Leverage'.

De acordo com @morettinpedroalbertoEstatisticaCienciaDados2022, 'Uma das ferramentas mais úteis para a avaliação da qualidade do ajuste de modelos de regressão é o **gráfico de resíduos** em que os resíduos são dispostos no eixo das ordenadas e os correspondentes valores da variável explicativa no eixo das abscissas (..) Os resíduos padronizados são adimensionais e têm variância igual a 1, independentemente da variância dos erros. Além disso, para erros com distribuição normal, cerca de 99% dos resíduos padronizados tem valor entre -3 e +3'.

O gráfico Normal Q-Q ou o teste de Shapiro-Wilk permitem verificar se os erros possuem distribuição normal.

```{r}

stats::shapiro.test(mod_simples[['residuals']])
```

Levando em conta que o teste de Shapiro-Wilk considera:

H0: distribuição dos dados = normal -------> p > 0,05
Ha: distribuição dos dados != normal ------> p <=0,05

Logo, rejeitando a hipótese nula temos que a distribuição dos resíduos não é normal. A mesma conclusão pode ser obtida analisando o Q-Q plot.

A partir do gráfico 'Residuals x Leverage', os dados que extrapolam os valores de -3 e +3 são identificados como *outliers* como os casos #369, #366 e #365. Estes números representam o número da linha do dado na base de dados.
Entretanto, pelo gráfico não existem pontos influentes ou pontos alavanca (*high leverage points*). Note que pouco vemos as linhas de distância de Cook (linha tracejada no canto superior direito) e todos os casos estão dentro das linhas de distância de Cook


```{r}

# EXISTÊNCIA DE OUTLIERS NOS RESÍDUOS
summary(stats::rstandard(mod_simples))
```

Os mínimos e os máximo extrapolam os limites -3 e +3, o que indica a existência de pontos discrepantes.


## Exercício 8

Ajuste um modelo `mod_multiplo` para `medv` explicado por `rm` e `crim`. Consulte o `summary(mod_multiplo)` em seguida.

```{r label = 'modelo_multiplos_atributos'}

mod_multiplo <- stats::lm(medv ~ rm + crim, data = MASS::Boston)

summary(mod_multiplo)

```

```{r label = graficos_mod_multiplo}
#| fig.align = 'center',
#| out.width = '90%'

op <- par(bg = '#000000')

graphics::par(mfrow = c(1,1), bty = 'l', col = '#FFFFFF')
plot(mod_multiplo, bg = par('bg'), col = '#EAC435', col.axis = "#FFFFFF", col.lab = "thistle")

```
<br><br>

Conforme o *post* @UnderstandingDiagnosticPlots, de Bommae King, da Biblioteca da Universidade da Virginia, o gráfico 'Residuals x Fitted' nos mostra que a existência de uma relação linear entre a variável resposta e a variável explicativa ocorre quando encontramos resíduos igualmente espalhados em torno de uma linha horizontal sem padrões distintos, sendo isto é uma boa indicação de que as variáveis possuem relação linear. 

## Exercício 9

Qual modelo ficou melhor: `mod_simples` ou `mod_multiplo`? Qual critério você utilizou para decidir o melhor?

Conforme @morettinpedroalbertoEstatisticaCienciaDados2022, 'Uma vez ajustado o modelo, convém avaliar a qualidade do ajuste e um dos indicadores mais utilizados para essa finalidade é o **coeficiente de determinação** definido como:

$$R^{2} = \frac{SQTot - SQRes}{SQTot} = \frac{SQReg}{SQTot} = 1 - \frac{SQRes}{SQTot},$$
(..) Em essência, esse coeficiente mede a porcentagem da variação total dos valores da variável resposta (yi) em relação à sua média ($\bar{y}$) explicada pelo modelo de regressão'.

Segundo @pianezzerguilhermeaugustoModelagemEstatistica2020, 'pode-se provar que R^2^ está contido entre 0 e 1. Alguns livros chamam de *coeficiente de determinação* o termo' R, tal que $-1 \le R \le 1$; entretanto, utilizar R^2^, tal que $0 \le R^{2} \le 1$ facilita a análise ao evitar operar com números negativos. Dessa forma, podemos afirmar que quanto mais $R^{2} \to 1$, mais forte é o poder explicativo do modelo linear. Quanto mais $R^{2} \to 0$, menos podemos confiar no modelo, visto que os dados não se aproximam da reta."

Na tabela abaixo, temos os resultados dos modelos de regressão linear simple e múltiplo.

```{r}

sjPlot::tab_model(mod_simples, mod_multiplo)

```

<br>
O modelo `mod_multiplo` ficou melhor, considerando que possui melhor coeficiente de determinação ($R^{2}$) de 0,542, melhor que o obtido pelo modelos simples, cujo coeficiente de determinação foi de 0,48.


## Exercício 10

Ajuste um modelo `mod_completo` para `medv` explicado por todas as demais colunas. DICA: na fórmula `medv ~ .`, o ponto significa "todas as variáveis, tirando medv".

a) Consulte o `summary(mod_completo)` em seguida.
b) Qual modelo ficou melhor: `mod_simples`, `mod_multiplo` ou `mod_completo`?
c) O valor estimado para o termo `rm` variou entre os três modelos? Por qual razão você acha que isso aconteceu?

```{r label = mod_completo}

mod_completo <- stats::lm(medv ~ ., data = MASS::Boston)

summary(mod_completo)

```


```{r}
#| fig.align = 'center',
#| out.width = '90%'

op <- par(bg = '#000000')

graphics::par(mfrow = c(1,1), bty = 'l', col = '#FFFFFF')
plot(mod_completo, bg = par('bg'), col = '#EAC435', col.axis = "#FFFFFF", col.lab = "thistle") 
```
<br>
Verificar a existência de correlação entre as variáveis que permitam sua exclusão

```{r}

x <- MASS::Boston[1:13]

caret::findLinearCombos(x)
```
 
Constata-se inexistência de colinearidade que permita a exclusão de variáveis.


Verificar a existência de correlação entre variáveis que permita o agrupamento das variáveis.
```{r}

car::vif(mod_completo)
```


```{r}
tax_rad_indus_dis_nox <-  MASS::Boston$tax + MASS::Boston$rad + MASS::Boston$indus + MASS::Boston$dis + MASS::Boston$nox
age_lstat <- MASS::Boston$age + MASS::Boston$lstat

modelo_completo_v2 <- lm(medv ~ crim + zn + chas + rm + age_lstat + ptratio + black + tax_rad_indus_dis_nox, data = MASS::Boston)

summary(modelo_completo_v2)


car::vif(modelo_completo_v2)

```




```{r}
#| fig.align = 'center',
#| out.width = '90%'

op <- par(bg = '#000000')

graphics::par(mfrow = c(1,1), bty = 'l', col = '#FFFFFF')
plot(modelo_completo_v2, bg = par('bg'), col = '#EAC435', col.axis = "#FFFFFF", col.lab = "thistle") 

```

## Referências Bibliográficas